"""
Streamlit UI + RAG-—á–∞—Ç —Å retriever + llm –Ω–∞–ø—Ä—è–º—É—é.

Stage 3: Core RAG logic (—Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ UI).
Stage 4: main() + Streamlit UI.
"""

import json
import os

import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM


# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
DEFAULT_INDEX_DIR = "rag_index/"
DEFAULT_TOP_K = 8  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 4 –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
DEFAULT_RERANK_TOP_K = 4  # –ü–æ—Å–ª–µ reranking –æ—Å—Ç–∞–≤–ª—è–µ–º –ª—É—á—à–∏–µ 4
DEFAULT_OLLAMA_MODEL = "qwen2.5:14b"  # –õ—É—á—à–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: qwen2.5:7b
DEFAULT_EMBED_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
ENABLE_RERANKING = False  # –û—Ç–∫–ª—é—á–µ–Ω–æ: –ª—É—á—à–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –í–°–ï —á–∞–Ω–∫–∏

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å Chain-of-Thought
SYSTEM_PROMPT = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–Ω–∏–≥.

–ú–ï–¢–û–î –û–¢–í–ï–¢–ê (–≤—ã–ø–æ–ª–Ω—è–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ):

–®–ê–ì 1 ‚Äî –ò–ó–í–õ–ï–ß–ï–ù–ò–ï: –ù–∞–π–¥–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –í–°–ï —ç–ª–µ–º–µ–Ω—Ç—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –≤–æ–ø—Ä–æ—Å–æ–º:
- –¢–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
- –ü—Ä–∏–Ω—Ü–∏–ø—ã –∏ –ø—Ä–∞–≤–∏–ª–∞
- –§–æ—Ä–º—É–ª—ã –∏ –º–µ—Ç–æ–¥—ã —Ä–∞—Å—á—ë—Ç–∞
- –ü—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã
- –ß–∏—Å–ª–∞ –∏ —Ñ–∞–∫—Ç—ã

–®–ê–ì 2 ‚Äî –ê–ù–ê–õ–ò–ó: –î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏, –∫–∞–∫ –æ–Ω –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–®–ê–ì 3 ‚Äî –°–ò–ù–¢–ï–ó: –û–±—ä–µ–¥–∏–Ω–∏ –≤—Å—ë –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç.

–ü–†–ê–í–ò–õ–ê:
- –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ
- –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –í–°–ï —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ø–æ –Ω–∏–º
- –ò—â–∏ —Ç–∞–±–ª–∏—Ü—ã (—Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ "–ù–∞–∑–≤–∞–Ω–∏–µ ... –ß–∏—Å–ª–æ") –∏ –∏–∑–≤–ª–µ–∫–∞–π –í–°–ï —Å—Ç—Ä–æ–∫–∏
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
- –ù–ï –¥–æ–±–∞–≤–ª—è–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ —Ç–µ–∫—Å—Ç ‚Äî –æ–Ω–∏ –ø–æ–∫–∞–∂—É—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏ "–í –∫–Ω–∏–≥–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É"

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–Ω–∏–≥:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç:"""


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è env ---

def get_env_int(name: str, default: int) -> int:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ—Ç int –∏–∑ env."""
    value = os.getenv(name)
    if value is None:
        return default
    try:
        return int(value)
    except ValueError:
        return default


def get_env_str(name: str, default: str) -> str:
    """–ß–∏—Ç–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ env —Å –¥–µ—Ñ–æ–ª—Ç–æ–º."""
    return os.getenv(name, default)


# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞ ---

def load_index_config(index_dir: str) -> dict | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç config.json —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Å–±–æ—Ä–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç.
    """
    config_path = os.path.join(index_dir, "config.json")
    if not os.path.exists(config_path):
        return None
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏
    required = ["embed_model", "chunk_size", "chunk_overlap"]
    for key in required:
        if key not in config:
            raise RuntimeError(
                f"‚ùå –í config.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á '{key}'.\n"
                f"   –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –∏–Ω–¥–µ–∫—Å: python rag_setup.py"
            )
    return config


def get_embeddings(config: dict) -> HuggingFaceEmbeddings:
    """
    –°–æ–∑–¥–∞—ë—Ç embeddings –∏—Å–ø–æ–ª—å–∑—É—è embed_model –ò–ó CONFIG (–Ω–µ –∏–∑ env!).
    –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –∏ –ø—Ä–∏ query.
    """
    model_name = config["embed_model"]
    return HuggingFaceEmbeddings(model_name=model_name)


def check_embed_model_mismatch(config: dict) -> bool:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç config["embed_model"] —Å os.getenv("EMBED_MODEL").
    –ï—Å–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True (–ø–æ–∫–∞–∑–∞—Ç—å warning).
    """
    env_model = os.getenv("EMBED_MODEL")
    if env_model is None:
        return False
    return env_model != config["embed_model"]


@st.cache_resource
def load_index(index_dir: str, embed_model: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç FAISS –∏–Ω–¥–µ–∫—Å —Å –¥–∏—Å–∫–∞.
    Embeddings —Å–æ–∑–¥–∞—é—Ç—Å—è –ó–î–ï–°–¨ –û–î–ò–ù –†–ê–ó.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ—Ç.
    
    –í–ù–ò–ú–ê–ù–ò–ï: allow_dangerous_deserialization=True –±–µ–∑–æ–ø–∞—Å–Ω–æ
    –¢–û–õ–¨–ö–û –¥–ª—è –≤–∞—à–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞. –ù–µ –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ —á—É–∂–∏–µ –∏–Ω–¥–µ–∫—Å—ã!
    """
    index_path = os.path.join(index_dir, "index.faiss")
    if not os.path.exists(index_path):
        return None
    
    embeddings = HuggingFaceEmbeddings(model_name=embed_model)
    vectorstore = FAISS.load_local(
        index_dir,
        embeddings,
        allow_dangerous_deserialization=True  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–≤–æ–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞!
    )
    return vectorstore


def get_retriever(vectorstore, top_k: int):
    """
    –°–æ–∑–¥–∞—ë—Ç retriever —Å –∑–∞–¥–∞–Ω–Ω—ã–º k.
    –í–ê–ñ–ù–û: k –∑–∞–¥–∞—ë—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ retriever, –ù–ï –ø—Ä–∏ –≤—ã–∑–æ–≤–µ.
    """
    return vectorstore.as_retriever(search_kwargs={"k": top_k})


# --- LLM ---

@st.cache_resource
def get_llm(model: str) -> OllamaLLM:
    """–°–æ–∑–¥–∞—ë—Ç LLM –∏–∑ Ollama."""
    # OLLAMA_BASE_URL –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–¥–∞–ª—ë–Ω–Ω—É—é Ollama (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ ngrok)
    base_url = get_env_str("OLLAMA_BASE_URL", "http://localhost:11434")
    return OllamaLLM(
        base_url=base_url,
        model=model,
        temperature=0,
    )


def check_ollama_connection(llm: OllamaLLM) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π GET –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ invoke –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏.
    """
    import urllib.request
    import urllib.error
    
    base_url = get_env_str("OLLAMA_BASE_URL", "http://localhost:11434")
    try:
        req = urllib.request.Request(f"{base_url}/api/tags", method="GET")
        with urllib.request.urlopen(req, timeout=5) as response:
            return response.status == 200
    except Exception:
        return False


# --- –ò—Å—Ç–æ—Ä–∏—è –∏ –ø—Ä–æ–º–ø—Ç ---

def build_history_text(messages: list[dict], max_pairs: int = 3) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç UI-–∏—Å—Ç–æ—Ä–∏—é –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
    –ë–µ—Ä—ë—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_pairs –ø–∞—Ä (user, assistant).
    –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
    """
    if not messages:
        return ""
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã user/assistant
    pairs = []
    i = 0
    while i < len(messages) - 1:
        if messages[i].get("role") == "user" and messages[i + 1].get("role") == "assistant":
            pairs.append((messages[i]["content"], messages[i + 1]["content"]))
            i += 2
        else:
            i += 1
    
    if not pairs:
        return ""
    
    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_pairs
    pairs = pairs[-max_pairs:]
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
    lines = []
    for user_msg, assistant_msg in pairs:
        lines.append(f"–í–æ–ø—Ä–æ—Å: {user_msg}")
        lines.append(f"–û—Ç–≤–µ—Ç: {assistant_msg}")
        lines.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏
    
    return "\n".join(lines).strip()


def build_full_question(user_question: str, messages: list[dict], max_pairs: int = 3) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–ª—è retriever.
    """
    history_text = build_history_text(messages, max_pairs)
    if history_text:
        return f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥:\n{history_text}\n\n–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: {user_question}"
    return user_question


def format_context(docs: list) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π "X –∏–∑ Y".
    –ü–æ—Ä—è–¥–æ–∫: –º–µ–Ω–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞, —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π ‚Äî –≤ –∫–æ–Ω—Ü–µ.
    (LLM –ª—É—á—à–µ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç –∫–æ–Ω–µ—Ü –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî "recency bias")
    """
    if not docs:
        return ""
    
    total = len(docs)
    # –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º: —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –±—É–¥–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–º
    reversed_docs = list(reversed(docs))
    
    fragments = []
    for i, doc in enumerate(reversed_docs, 1):
        # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page_label = doc.metadata.get("page_label")
        if not page_label:
            page_num = doc.metadata.get("page")
            page_label = str(page_num + 1) if page_num is not None else "?"
        
        # "X –∏–∑ Y" —Å–æ–∑–¥–∞—ë—Ç –æ—â—É—â–µ–Ω–∏–µ —á–µ–∫-–ª–∏—Å—Ç–∞ –¥–ª—è LLM
        header = f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} –∏–∑ {total}, —Å—Ç—Ä. {page_label}]"
        fragments.append(f"{header}\n{doc.page_content}")
    
    return "\n\n---\n\n".join(fragments)


def build_prompt(context: str, question: str) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM."""
    return SYSTEM_PROMPT.format(context=context, question=question)


# --- LLM-based Reranking ---

RERANK_PROMPT = """–û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –∫ –≤–æ–ø—Ä–æ—Å—É –ø–æ —à–∫–∞–ª–µ 0-10.
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û —á–∏—Å–ª–æ–º –æ—Ç 0 –¥–æ 10.

–í–æ–ø—Ä–æ—Å: {question}

–¢–µ–∫—Å—Ç: {chunk}

–û—Ü–µ–Ω–∫–∞ (0-10):"""


def rerank_docs(docs: list, question: str, llm, top_k: int = 4) -> list:
    """
    LLM-based reranking: –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top_k –ª—É—á—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
    
    –≠—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å:
    1. Retriever –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–Ω–æ–≥–æ —á–∞–Ω–∫–æ–≤ (—à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç)
    2. LLM –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π –∏ –æ—Ç–±–∏—Ä–∞–µ—Ç —Å–∞–º—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ (—Ç–æ—á–Ω–æ—Å—Ç—å)
    """
    if not docs or len(docs) <= top_k:
        return docs
    
    scored_docs = []
    
    for doc in docs:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (—ç–∫–æ–Ω–æ–º–∏–º —Ç–æ–∫–µ–Ω—ã)
        chunk_preview = doc.page_content[:800]
        prompt = RERANK_PROMPT.format(question=question, chunk=chunk_preview)
        
        try:
            response = llm.invoke(prompt)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏–∑ –æ—Ç–≤–µ—Ç–∞
            score = extract_score(response)
            scored_docs.append((score, doc))
        except Exception:
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ –¥–∞—ë–º —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª
            scored_docs.append((5, doc))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –æ—Ü–µ–Ω–∫–∏
    scored_docs.sort(key=lambda x: x[0], reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º top_k –ª—É—á—à–∏—Ö
    return [doc for score, doc in scored_docs[:top_k]]


def extract_score(response: str) -> int:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤—É—é –æ—Ü–µ–Ω–∫—É –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM."""
    import re
    # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ –≤ –æ—Ç–≤–µ—Ç–µ
    match = re.search(r'\b(\d+)\b', response.strip())
    if match:
        score = int(match.group(1))
        return min(max(score, 0), 10)  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 0-10
    return 5  # Default


# --- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ---

def format_source(doc) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –ï–î–ò–ù–´–ô —Ñ–æ—Ä–º–∞—Ç: "book.pdf [—Å—Ç—Ä. 23]"
    """
    filename = os.path.basename(doc.metadata.get("source", "unknown"))
    
    # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º page_label, –∏–Ω–∞—á–µ page+1
    page_label = doc.metadata.get("page_label")
    if page_label:
        page = page_label
    else:
        page_num = doc.metadata.get("page")
        page = str(page_num + 1) if page_num is not None else "?"
    
    return f"{filename} [—Å—Ç—Ä. {page}]"


def format_sources(docs: list) -> list[str]:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è.
    """
    seen = set()
    result = []
    for doc in docs:
        source = format_source(doc)
        if source not in seen:
            seen.add(source)
            result.append(source)
    return result


# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---

def ask_question(
    retriever,
    llm,
    question: str,
    messages: list[dict],
) -> tuple[str, list]:
    """
    –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É—è retriever –∏ llm –ù–ê–ü–†–Ø–ú–£–Æ.
    
    –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º RetrievalQA chain!
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (answer, docs) –≥–¥–µ docs ‚Äî —Å–ø–∏—Å–æ–∫ Document –¥–ª—è sources.
    """
    # 1. –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π
    full_question = build_full_question(question, messages)
    
    # 2. –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã (—à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç)
    # –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ ‚Äî invoke, fallback ‚Äî get_relevant_documents
    try:
        docs = retriever.invoke(full_question)
    except AttributeError:
        docs = retriever.get_relevant_documents(full_question)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Å–ø–∏—Å–æ–∫
    if not isinstance(docs, list):
        docs = list(docs) if docs else []
    
    # 3. –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚Äî –ù–ï –≤—ã–∑—ã–≤–∞–µ–º LLM
    if not docs:
        return "–í –∫–Ω–∏–≥–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É.", []
    
    # 3.5 Reranking: LLM –æ—Ç–±–∏—Ä–∞–µ—Ç —Å–∞–º—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
    if ENABLE_RERANKING and len(docs) > DEFAULT_RERANK_TOP_K:
        docs = rerank_docs(
            docs=docs,
            question=full_question,
            llm=llm,
            top_k=DEFAULT_RERANK_TOP_K
        )
    
    # 4. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context = format_context(docs)
    
    # 5. –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt = build_prompt(context, full_question)
    
    # 6. –í—ã–∑—ã–≤–∞–µ–º LLM
    answer = llm.invoke(prompt)
    
    # 7. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    return answer, docs


# --- Stage 4: Streamlit UI ---

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="RAG —á–∞—Ç–±–æ—Ç –ø–æ PDF",
        page_icon="üìö",
        layout="wide",
    )
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üìö RAG —á–∞—Ç–±–æ—Ç –ø–æ PDF")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∏–∑ env
    index_dir = get_env_str("INDEX_DIR", DEFAULT_INDEX_DIR)
    books_dir = get_env_str("BOOKS_DIR", "books/")
    top_k = get_env_int("TOP_K", DEFAULT_TOP_K)
    ollama_model = get_env_str("OLLAMA_MODEL", DEFAULT_OLLAMA_MODEL)
    
    # --- Sidebar ---
    with st.sidebar:
        st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        
        # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç", use_container_width=True):
            st.session_state.messages = []
            st.rerun()
        
        st.divider()
        
        # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
        if st.button("üîÑ –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å", use_container_width=True):
            with st.spinner("–ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞..."):
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å circular import
                from rag_setup import rebuild_full_index
                
                success = rebuild_full_index(books_dir, index_dir)
                
                if success:
                    st.cache_resource.clear()
                    st.success("‚úÖ –ò–Ω–¥–µ–∫—Å –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω!")
                    st.rerun()
                else:
                    st.error(f"‚ùå –í –ø–∞–ø–∫–µ {books_dir} –Ω–µ—Ç PDF —Ñ–∞–π–ª–æ–≤.")
        
        st.divider()
        
        # –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞
        st.subheader("üìä –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞")
        config = load_index_config(index_dir)
        
        if config:
            st.success("‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω")
            st.caption(f"**PDF:** {config.get('pdf_count', '?')}")
            st.caption(f"**–ß–∞–Ω–∫–æ–≤:** {config.get('chunk_count', '?')}")
            st.caption(f"**chunk_size:** {config.get('chunk_size', '?')}")
            st.caption(f"**overlap:** {config.get('chunk_overlap', '?')}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
            if check_embed_model_mismatch(config):
                st.warning("‚ö†Ô∏è EMBED_MODEL –≤ env –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç config.json")
        else:
            st.warning("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω")
            st.caption("–ü–æ–ª–æ–∂–∏—Ç–µ PDF –≤ books/ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å'")
    
    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏–Ω–¥–µ–∫—Å–∞ ---
    if not config:
        st.warning(
            "üìÇ **–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω.**\n\n"
            "1. –ü–æ–ª–æ–∂–∏—Ç–µ PDF —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É `books/`\n"
            "2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É **–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å** –≤ sidebar\n\n"
            "–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: `python rag_setup.py`"
        )
        st.stop()
    
    # --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ ---
    try:
        vectorstore = load_index(index_dir, config["embed_model"])
        if not vectorstore:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å. –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –µ–≥–æ.")
            st.stop()
        
        retriever = get_retriever(vectorstore, top_k)
        llm = get_llm(ollama_model)
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        st.stop()
    
    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama ---
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –∏–ª–∏ –µ—Å–ª–∏ —Ñ–ª–∞–≥ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    if "ollama_checked" not in st.session_state:
        with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama..."):
            if not check_ollama_connection(llm):
                st.error(
                    "‚ùå **Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.**\n\n"
                    "–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:\n"
                    "1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama: `ollama serve`\n"
                    f"2. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å: `ollama pull {ollama_model}`"
                )
                st.stop()
            st.session_state.ollama_checked = True
    
    # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if message.get("sources"):
                with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                    for source in message["sources"]:
                        st.caption(f"‚Ä¢ {source}")
    
    # --- –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
    if user_input := st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –∫–Ω–∏–≥–∞–º..."):
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
        })
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        with st.chat_message("assistant"):
            with st.spinner("–î—É–º–∞—é..."):
                try:
                    # –ü–µ—Ä–µ–¥–∞—ë–º –∏—Å—Ç–æ—Ä–∏—é –ë–ï–ó —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–Ω–æ —É–∂–µ –≤ question)
                    history = st.session_state.messages[:-1]
                    answer, docs = ask_question(retriever, llm, user_input, history)
                    sources = format_sources(docs)
                    
                except RuntimeError as e:
                    answer = f"‚ùå –û—à–∏–±–∫–∞: {e}"
                    sources = []
                except Exception as e:
                    answer = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"
                    sources = []
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            st.markdown(answer)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            if sources:
                with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏", expanded=True):
                    for source in sources:
                        st.caption(f"‚Ä¢ {source}")
            else:
                st.caption("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: (–Ω–µ—Ç)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({
            "role": "assistant",
            "content": answer,
            "sources": sources,
        })


if __name__ == "__main__":
    main()
