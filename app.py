"""
Streamlit UI + RAG-—á–∞—Ç —Å retriever + llm –Ω–∞–ø—Ä—è–º—É—é.

Stage 3: Core RAG logic (—Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ UI).
Stage 4: main() + Streamlit UI.
"""

import json
import os

import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM


# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
DEFAULT_INDEX_DIR = "rag_index/"
DEFAULT_TOP_K = 8  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 4 –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
DEFAULT_OLLAMA_MODEL = "llama3"
DEFAULT_EMBED_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–∏–∑ TECHNICAL_SPEC.md)
SYSTEM_PROMPT = """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∫–Ω–∏–≥.

–ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–∫–∞–∫–∏–µ –≤–∏–¥—ã X –µ—Å—Ç—å"), –∏—â–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã X –∏ –ø–µ—Ä–µ—á–∏—Å–ª—è–π –∏—Ö.
2. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –†–£–°–°–ö–û–ú —è–∑—ã–∫–µ, –¥–∞–∂–µ –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã.
3. –î–∞–≤–∞–π –ü–û–î–†–û–ë–ù–´–ï –∏ –†–ê–ó–í–Å–†–ù–£–¢–´–ï –æ—Ç–≤–µ—Ç—ã. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å —Å–ø–∏—Å–∫–∏ –∏–ª–∏ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è ‚Äî –ø—Ä–∏–≤–æ–¥–∏ –∏—Ö –ü–û–õ–ù–û–°–¢–¨–Æ.
4. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ù–ï–¢ –ù–ò–ö–ê–ö–û–ô —Å–≤—è–∑–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ ‚Äî –æ—Ç–≤–µ—á–∞–π: "–í –∫–Ω–∏–≥–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É." –ù–æ –µ—Å–ª–∏ –µ—Å—Ç—å –°–í–Ø–ó–ê–ù–ù–´–ï —Ç–µ—Ä–º–∏–Ω—ã –∏–ª–∏ –ø—Ä–∏–º–µ—Ä—ã ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞.
5. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
6. –ù–ï –¥–æ–±–∞–≤–ª—è–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏/—Å—Å—ã–ª–∫–∏/—Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤ —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞. –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –±—É–¥—É—Ç –ø–æ–∫–∞–∑–∞–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.
7. –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –∏–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤.
8. –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: —Å–ø–∏—Å–∫–∏, –∞–±–∑–∞—Ü—ã –¥–ª—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏.

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–Ω–∏–≥:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç (–Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ):"""


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è env ---

def get_env_int(name: str, default: int) -> int:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ—Ç int –∏–∑ env."""
    value = os.getenv(name)
    if value is None:
        return default
    try:
        return int(value)
    except ValueError:
        return default


def get_env_str(name: str, default: str) -> str:
    """–ß–∏—Ç–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ env —Å –¥–µ—Ñ–æ–ª—Ç–æ–º."""
    return os.getenv(name, default)


# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞ ---

def load_index_config(index_dir: str) -> dict | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç config.json —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Å–±–æ—Ä–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç.
    """
    config_path = os.path.join(index_dir, "config.json")
    if not os.path.exists(config_path):
        return None
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏
    required = ["embed_model", "chunk_size", "chunk_overlap"]
    for key in required:
        if key not in config:
            raise RuntimeError(
                f"‚ùå –í config.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á '{key}'.\n"
                f"   –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –∏–Ω–¥–µ–∫—Å: python rag_setup.py"
            )
    return config


def get_embeddings(config: dict) -> HuggingFaceEmbeddings:
    """
    –°–æ–∑–¥–∞—ë—Ç embeddings –∏—Å–ø–æ–ª—å–∑—É—è embed_model –ò–ó CONFIG (–Ω–µ –∏–∑ env!).
    –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–±–æ—Ä–∫–µ –∏ –ø—Ä–∏ query.
    """
    model_name = config["embed_model"]
    return HuggingFaceEmbeddings(model_name=model_name)


def check_embed_model_mismatch(config: dict) -> bool:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç config["embed_model"] —Å os.getenv("EMBED_MODEL").
    –ï—Å–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True (–ø–æ–∫–∞–∑–∞—Ç—å warning).
    """
    env_model = os.getenv("EMBED_MODEL")
    if env_model is None:
        return False
    return env_model != config["embed_model"]


@st.cache_resource
def load_index(index_dir: str, embed_model: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç FAISS –∏–Ω–¥–µ–∫—Å —Å –¥–∏—Å–∫–∞.
    Embeddings —Å–æ–∑–¥–∞—é—Ç—Å—è –ó–î–ï–°–¨ –û–î–ò–ù –†–ê–ó.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ—Ç.
    
    –í–ù–ò–ú–ê–ù–ò–ï: allow_dangerous_deserialization=True –±–µ–∑–æ–ø–∞—Å–Ω–æ
    –¢–û–õ–¨–ö–û –¥–ª—è –≤–∞—à–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞. –ù–µ –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ —á—É–∂–∏–µ –∏–Ω–¥–µ–∫—Å—ã!
    """
    index_path = os.path.join(index_dir, "index.faiss")
    if not os.path.exists(index_path):
        return None
    
    embeddings = HuggingFaceEmbeddings(model_name=embed_model)
    vectorstore = FAISS.load_local(
        index_dir,
        embeddings,
        allow_dangerous_deserialization=True  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–≤–æ–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞!
    )
    return vectorstore


def get_retriever(vectorstore, top_k: int):
    """
    –°–æ–∑–¥–∞—ë—Ç retriever —Å –∑–∞–¥–∞–Ω–Ω—ã–º k.
    –í–ê–ñ–ù–û: k –∑–∞–¥–∞—ë—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ retriever, –ù–ï –ø—Ä–∏ –≤—ã–∑–æ–≤–µ.
    """
    return vectorstore.as_retriever(search_kwargs={"k": top_k})


# --- LLM ---

@st.cache_resource
def get_llm(model: str) -> OllamaLLM:
    """–°–æ–∑–¥–∞—ë—Ç LLM –∏–∑ Ollama."""
    # OLLAMA_BASE_URL –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–¥–∞–ª—ë–Ω–Ω—É—é Ollama (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ ngrok)
    base_url = get_env_str("OLLAMA_BASE_URL", "http://localhost:11434")
    return OllamaLLM(
        base_url=base_url,
        model=model,
        temperature=0,
    )


def check_ollama_connection(llm: OllamaLLM) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π GET –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ invoke –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏.
    """
    import urllib.request
    import urllib.error
    
    base_url = get_env_str("OLLAMA_BASE_URL", "http://localhost:11434")
    try:
        req = urllib.request.Request(f"{base_url}/api/tags", method="GET")
        with urllib.request.urlopen(req, timeout=5) as response:
            return response.status == 200
    except Exception:
        return False


# --- –ò—Å—Ç–æ—Ä–∏—è –∏ –ø—Ä–æ–º–ø—Ç ---

def build_history_text(messages: list[dict], max_pairs: int = 3) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç UI-–∏—Å—Ç–æ—Ä–∏—é –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
    –ë–µ—Ä—ë—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_pairs –ø–∞—Ä (user, assistant).
    –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
    """
    if not messages:
        return ""
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã user/assistant
    pairs = []
    i = 0
    while i < len(messages) - 1:
        if messages[i].get("role") == "user" and messages[i + 1].get("role") == "assistant":
            pairs.append((messages[i]["content"], messages[i + 1]["content"]))
            i += 2
        else:
            i += 1
    
    if not pairs:
        return ""
    
    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_pairs
    pairs = pairs[-max_pairs:]
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
    lines = []
    for user_msg, assistant_msg in pairs:
        lines.append(f"–í–æ–ø—Ä–æ—Å: {user_msg}")
        lines.append(f"–û—Ç–≤–µ—Ç: {assistant_msg}")
        lines.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏
    
    return "\n".join(lines).strip()


def build_full_question(user_question: str, messages: list[dict], max_pairs: int = 3) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–ª—è retriever.
    """
    history_text = build_history_text(messages, max_pairs)
    if history_text:
        return f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥:\n{history_text}\n\n–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: {user_question}"
    return user_question


def format_context(docs: list) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    return "\n\n---\n\n".join(doc.page_content for doc in docs)


def build_prompt(context: str, question: str) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM."""
    return SYSTEM_PROMPT.format(context=context, question=question)


# --- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ---

def format_source(doc) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –ï–î–ò–ù–´–ô —Ñ–æ—Ä–º–∞—Ç: "book.pdf [—Å—Ç—Ä. 23]"
    """
    filename = os.path.basename(doc.metadata.get("source", "unknown"))
    
    # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º page_label, –∏–Ω–∞—á–µ page+1
    page_label = doc.metadata.get("page_label")
    if page_label:
        page = page_label
    else:
        page_num = doc.metadata.get("page")
        page = str(page_num + 1) if page_num is not None else "?"
    
    return f"{filename} [—Å—Ç—Ä. {page}]"


def format_sources(docs: list) -> list[str]:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è.
    """
    seen = set()
    result = []
    for doc in docs:
        source = format_source(doc)
        if source not in seen:
            seen.add(source)
            result.append(source)
    return result


# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---

def ask_question(
    retriever,
    llm,
    question: str,
    messages: list[dict],
) -> tuple[str, list]:
    """
    –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É—è retriever –∏ llm –ù–ê–ü–†–Ø–ú–£–Æ.
    
    –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º RetrievalQA chain!
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (answer, docs) –≥–¥–µ docs ‚Äî —Å–ø–∏—Å–æ–∫ Document –¥–ª—è sources.
    """
    # 1. –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π
    full_question = build_full_question(question, messages)
    
    # 2. –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
    # –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ ‚Äî invoke, fallback ‚Äî get_relevant_documents
    try:
        docs = retriever.invoke(full_question)
    except AttributeError:
        docs = retriever.get_relevant_documents(full_question)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Å–ø–∏—Å–æ–∫
    if not isinstance(docs, list):
        docs = list(docs) if docs else []
    
    # 3. –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚Äî –ù–ï –≤—ã–∑—ã–≤–∞–µ–º LLM
    if not docs:
        return "–í –∫–Ω–∏–≥–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É.", []
    
    # 4. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context = format_context(docs)
    
    # 5. –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt = build_prompt(context, full_question)
    
    # 6. –í—ã–∑—ã–≤–∞–µ–º LLM
    answer = llm.invoke(prompt)
    
    # 7. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    return answer, docs


# --- Stage 4: Streamlit UI ---

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="RAG —á–∞—Ç–±–æ—Ç –ø–æ PDF",
        page_icon="üìö",
        layout="wide",
    )
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üìö RAG —á–∞—Ç–±–æ—Ç –ø–æ PDF")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∏–∑ env
    index_dir = get_env_str("INDEX_DIR", DEFAULT_INDEX_DIR)
    books_dir = get_env_str("BOOKS_DIR", "books/")
    top_k = get_env_int("TOP_K", DEFAULT_TOP_K)
    ollama_model = get_env_str("OLLAMA_MODEL", DEFAULT_OLLAMA_MODEL)
    
    # --- Sidebar ---
    with st.sidebar:
        st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        
        # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç", use_container_width=True):
            st.session_state.messages = []
            st.rerun()
        
        st.divider()
        
        # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
        if st.button("üîÑ –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å", use_container_width=True):
            with st.spinner("–ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞..."):
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å circular import
                from rag_setup import rebuild_full_index
                
                success = rebuild_full_index(books_dir, index_dir)
                
                if success:
                    st.cache_resource.clear()
                    st.success("‚úÖ –ò–Ω–¥–µ–∫—Å –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω!")
                    st.rerun()
                else:
                    st.error(f"‚ùå –í –ø–∞–ø–∫–µ {books_dir} –Ω–µ—Ç PDF —Ñ–∞–π–ª–æ–≤.")
        
        st.divider()
        
        # –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞
        st.subheader("üìä –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞")
        config = load_index_config(index_dir)
        
        if config:
            st.success("‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω")
            st.caption(f"**PDF:** {config.get('pdf_count', '?')}")
            st.caption(f"**–ß–∞–Ω–∫–æ–≤:** {config.get('chunk_count', '?')}")
            st.caption(f"**chunk_size:** {config.get('chunk_size', '?')}")
            st.caption(f"**overlap:** {config.get('chunk_overlap', '?')}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
            if check_embed_model_mismatch(config):
                st.warning("‚ö†Ô∏è EMBED_MODEL –≤ env –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç config.json")
        else:
            st.warning("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω")
            st.caption("–ü–æ–ª–æ–∂–∏—Ç–µ PDF –≤ books/ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å'")
    
    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏–Ω–¥–µ–∫—Å–∞ ---
    if not config:
        st.warning(
            "üìÇ **–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω.**\n\n"
            "1. –ü–æ–ª–æ–∂–∏—Ç–µ PDF —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É `books/`\n"
            "2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É **–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å** –≤ sidebar\n\n"
            "–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: `python rag_setup.py`"
        )
        st.stop()
    
    # --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ ---
    try:
        vectorstore = load_index(index_dir, config["embed_model"])
        if not vectorstore:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å. –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –µ–≥–æ.")
            st.stop()
        
        retriever = get_retriever(vectorstore, top_k)
        llm = get_llm(ollama_model)
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        st.stop()
    
    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama ---
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –∏–ª–∏ –µ—Å–ª–∏ —Ñ–ª–∞–≥ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    if "ollama_checked" not in st.session_state:
        with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama..."):
            if not check_ollama_connection(llm):
                st.error(
                    "‚ùå **Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.**\n\n"
                    "–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:\n"
                    "1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama: `ollama serve`\n"
                    f"2. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å: `ollama pull {ollama_model}`"
                )
                st.stop()
            st.session_state.ollama_checked = True
    
    # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if message.get("sources"):
                with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                    for source in message["sources"]:
                        st.caption(f"‚Ä¢ {source}")
    
    # --- –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
    if user_input := st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –∫–Ω–∏–≥–∞–º..."):
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
        })
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        with st.chat_message("assistant"):
            with st.spinner("–î—É–º–∞—é..."):
                try:
                    # –ü–µ—Ä–µ–¥–∞—ë–º –∏—Å—Ç–æ—Ä–∏—é –ë–ï–ó —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–Ω–æ —É–∂–µ –≤ question)
                    history = st.session_state.messages[:-1]
                    answer, docs = ask_question(retriever, llm, user_input, history)
                    sources = format_sources(docs)
                    
                except RuntimeError as e:
                    answer = f"‚ùå –û—à–∏–±–∫–∞: {e}"
                    sources = []
                except Exception as e:
                    answer = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"
                    sources = []
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            st.markdown(answer)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            if sources:
                with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏", expanded=True):
                    for source in sources:
                        st.caption(f"‚Ä¢ {source}")
            else:
                st.caption("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: (–Ω–µ—Ç)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({
            "role": "assistant",
            "content": answer,
            "sources": sources,
        })


if __name__ == "__main__":
    main()
