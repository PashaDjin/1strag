"""
Streamlit UI + RAG-—á–∞—Ç —Å retriever + llm –Ω–∞–ø—Ä—è–º—É—é.

Stage 3: Core RAG logic (—Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ UI).
Stage 4: main() + Streamlit UI.
"""

import json
import os

import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM


# --- –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
DEFAULT_INDEX_DIR = "rag_index/"
DEFAULT_TOP_K = 20  # –£–≤–µ–ª–∏—á–µ–Ω–æ: —á–∞–Ω–∫–∏ 500 —Ç–æ–∫–µ–Ω–æ–≤ ‚Üí –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
DEFAULT_OLLAMA_MODEL = "qwen2.5:14b"  # –õ—É—á—à–∏–π –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: qwen2.5:7b
ENABLE_QUERY_EXPANSION = True  # –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å Chain-of-Thought
SYSTEM_PROMPT = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫. –¢–≤–æ—è –ï–î–ò–ù–°–¢–í–ï–ù–ù–ê–Ø –∑–∞–¥–∞—á–∞ ‚Äî –∏–∑–≤–ª–µ–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ.

‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ
- –ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ —Ü–∏—Ç–∏—Ä—É–π –∫–Ω–∏–≥—É
- –ï—Å–ª–∏ —Ñ–æ—Ä–º—É–ª–∞ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî —Ü–∏—Ç–∏—Ä—É–π –µ—ë –î–û–°–õ–û–í–ù–û
- –ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ‚Äî –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π, –Ω–∞–ø–∏—à–∏ "–≤ –∫–Ω–∏–≥–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ"

–®–ê–ì 1 ‚Äî –ò–ó–í–õ–ï–ß–ï–ù–ò–ï: –ü–µ—Ä–µ—á–∏—Ç–∞–π –ö–ê–ñ–î–´–ô —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏ –≤—ã–ø–∏—à–∏ –í–°–ï —Ç–µ—Ä–º–∏–Ω—ã/–ø–æ–Ω—è—Ç–∏—è –ø–æ —Ç–µ–º–µ –≤–æ–ø—Ä–æ—Å–∞.
–í–∞–∂–Ω–æ: –ø—Ä–æ—Å–º–æ—Ç—Ä–∏ –í–°–ï —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –º–µ–∂–¥—É –Ω–∏–º–∏!

–®–ê–ì 2 ‚Äî –ê–ù–ê–õ–ò–ó: –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞ –∫—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å (–ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É).

–®–ê–ì 3 ‚Äî –°–ò–ù–¢–ï–ó: –û–±—ä–µ–¥–∏–Ω–∏ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–æ —Å–ø–∏—Å–∫–æ–º.

–ó–ê–ü–†–ï–©–ï–ù–û:
‚ùå –ü—Ä–∏–¥—É–º—ã–≤–∞—Ç—å —Ñ–æ—Ä–º—É–ª—ã –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
‚ùå –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ù–ï –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
‚ùå –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å—Å—è –Ω–∞ 2-3 –ø—É–Ω–∫—Ç–∞—Ö ‚Äî –∏—â–∏ –í–°–Å

–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –∫–Ω–∏–≥:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–û—Ç–≤–µ—Ç (–°–¢–†–û–ì–û –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤—ã—à–µ):"""


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è env ---

def get_env_int(name: str, default: int) -> int:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ —á–∏—Ç–∞–µ—Ç int –∏–∑ env."""
    value = os.getenv(name)
    if value is None:
        return default
    try:
        return int(value)
    except ValueError:
        return default


def get_env_str(name: str, default: str) -> str:
    """–ß–∏—Ç–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –∏–∑ env —Å –¥–µ—Ñ–æ–ª—Ç–æ–º."""
    return os.getenv(name, default)


# --- –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥–∞ –∏ –∏–Ω–¥–µ–∫—Å–∞ ---

def load_index_config(index_dir: str) -> dict | None:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç config.json —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ —Å–±–æ—Ä–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç.
    """
    config_path = os.path.join(index_dir, "config.json")
    if not os.path.exists(config_path):
        return None
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = json.load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ embed_model ‚Äî –æ—Å—Ç–∞–ª—å–Ω–æ–µ –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
    if "embed_model" not in config:
        raise RuntimeError(
            "‚ùå –í config.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–ª—é—á 'embed_model'.\n"
            "   –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –∏–Ω–¥–µ–∫—Å: python rag_setup.py"
        )
    return config


def is_e5_model(model_name: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å E5 (—Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å—ã query:/passage:)."""
    return "e5" in model_name.lower()


class E5QueryEmbeddings(HuggingFaceEmbeddings):
    """
    –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ HuggingFaceEmbeddings, –¥–æ–±–∞–≤–ª—è—é—â–∞—è 'query: ' –ø—Ä–µ—Ñ–∏–∫—Å.
    E5 –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞–ª–∏—Å—å —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏ ‚Äî —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞!
    """
    def embed_query(self, text: str) -> list[float]:
        """–î–æ–±–∞–≤–ª—è–µ—Ç query: –ø—Ä–µ—Ñ–∏–∫—Å –ø–µ—Ä–µ–¥ –ø–æ–ª—É—á–µ–Ω–∏–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞."""
        return super().embed_query(f"query: {text}")


def check_embed_model_mismatch(config: dict) -> bool:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç config["embed_model"] —Å os.getenv("EMBED_MODEL").
    –ï—Å–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True (–ø–æ–∫–∞–∑–∞—Ç—å warning).
    """
    env_model = os.getenv("EMBED_MODEL")
    if env_model is None:
        return False
    return env_model != config["embed_model"]


@st.cache_resource
def load_index(index_dir: str, embed_model: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç FAISS –∏–Ω–¥–µ–∫—Å —Å –¥–∏—Å–∫–∞.
    Embeddings —Å–æ–∑–¥–∞—é—Ç—Å—è –ó–î–ï–°–¨ –û–î–ò–ù –†–ê–ó.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ –∏–Ω–¥–µ–∫—Å–∞ –Ω–µ—Ç.
    
    –í–ù–ò–ú–ê–ù–ò–ï: allow_dangerous_deserialization=True –±–µ–∑–æ–ø–∞—Å–Ω–æ
    –¢–û–õ–¨–ö–û –¥–ª—è –≤–∞—à–µ–≥–æ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞. –ù–µ –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ —á—É–∂–∏–µ –∏–Ω–¥–µ–∫—Å—ã!
    """
    index_path = os.path.join(index_dir, "index.faiss")
    if not os.path.exists(index_path):
        return None
    
    # –î–ª—è E5 –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ë—Ä—Ç–∫—É —Å query: –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
    if is_e5_model(embed_model):
        embeddings = E5QueryEmbeddings(model_name=embed_model)
    else:
        embeddings = HuggingFaceEmbeddings(model_name=embed_model)
    
    vectorstore = FAISS.load_local(
        index_dir,
        embeddings,
        allow_dangerous_deserialization=True  # –ë–µ–∑–æ–ø–∞—Å–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–≤–æ–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞!
    )
    return vectorstore


def get_retriever(vectorstore, top_k: int):
    """
    –°–æ–∑–¥–∞—ë—Ç retriever —Å –∑–∞–¥–∞–Ω–Ω—ã–º k.
    –í–ê–ñ–ù–û: k –∑–∞–¥–∞—ë—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ retriever, –ù–ï –ø—Ä–∏ –≤—ã–∑–æ–≤–µ.
    """
    return vectorstore.as_retriever(search_kwargs={"k": top_k})


# --- LLM ---

@st.cache_resource
def get_llm(model: str) -> OllamaLLM:
    """–°–æ–∑–¥–∞—ë—Ç LLM –∏–∑ Ollama."""
    # OLLAMA_BASE_URL –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–¥–∞–ª—ë–Ω–Ω—É—é Ollama (–Ω–∞–ø—Ä–∏–º–µ—Ä, —á–µ—Ä–µ–∑ ngrok)
    base_url = get_env_str("OLLAMA_BASE_URL", "http://localhost:11434")
    return OllamaLLM(
        base_url=base_url,
        model=model,
        temperature=0,
    )


def check_ollama_connection(llm: OllamaLLM) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π GET –∑–∞–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ invoke –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏.
    """
    import urllib.request
    import urllib.error
    
    base_url = get_env_str("OLLAMA_BASE_URL", "http://localhost:11434")
    try:
        req = urllib.request.Request(f"{base_url}/api/tags", method="GET")
        with urllib.request.urlopen(req, timeout=5) as response:
            return response.status == 200
    except Exception:
        return False


# --- –ò—Å—Ç–æ—Ä–∏—è –∏ –ø—Ä–æ–º–ø—Ç ---

def build_history_text(messages: list[dict], max_pairs: int = 3) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç UI-–∏—Å—Ç–æ—Ä–∏—é –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞.
    –ë–µ—Ä—ë—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_pairs –ø–∞—Ä (user, assistant).
    –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞ ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
    """
    if not messages:
        return ""
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø–∞—Ä—ã user/assistant
    pairs = []
    i = 0
    while i < len(messages) - 1:
        if messages[i].get("role") == "user" and messages[i + 1].get("role") == "assistant":
            pairs.append((messages[i]["content"], messages[i + 1]["content"]))
            i += 2
        else:
            i += 1
    
    if not pairs:
        return ""
    
    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ max_pairs
    pairs = pairs[-max_pairs:]
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º
    lines = []
    for user_msg, assistant_msg in pairs:
        lines.append(f"–í–æ–ø—Ä–æ—Å: {user_msg}")
        lines.append(f"–û—Ç–≤–µ—Ç: {assistant_msg}")
        lines.append("")  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏
    
    return "\n".join(lines).strip()


def build_full_question(user_question: str, messages: list[dict], max_pairs: int = 3) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π –¥–ª—è retriever.
    """
    history_text = build_history_text(messages, max_pairs)
    if history_text:
        return f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥:\n{history_text}\n\n–¢–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å: {user_question}"
    return user_question


def format_context(docs: list) -> str:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π "X –∏–∑ Y".
    –ü–æ—Ä—è–¥–æ–∫: –º–µ–Ω–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–Ω–∞—á–∞–ª–∞, —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π ‚Äî –≤ –∫–æ–Ω—Ü–µ.
    (LLM –ª—É—á—à–µ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç –∫–æ–Ω–µ—Ü –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ ‚Äî "recency bias")
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞ metadata:
    - –ù–æ–≤—ã–π (HybridChunker): section/headings
    - –°—Ç–∞—Ä—ã–π (legacy): page_label/page
    """
    if not docs:
        return ""
    
    total = len(docs)
    # –ü–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º: —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –±—É–¥–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–º
    reversed_docs = list(reversed(docs))
    
    fragments = []
    for i, doc in enumerate(reversed_docs, 1):
        # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: section –æ—Ç HybridChunker
        section = doc.metadata.get("section")
        if section:
            location = section
        else:
            # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: page number
            page_label = doc.metadata.get("page_label")
            if not page_label:
                page_num = doc.metadata.get("page")
                page_label = str(page_num + 1) if page_num is not None else "?"
            location = f"—Å—Ç—Ä. {page_label}"
        
        # "X –∏–∑ Y" —Å–æ–∑–¥–∞—ë—Ç –æ—â—É—â–µ–Ω–∏–µ —á–µ–∫-–ª–∏—Å—Ç–∞ –¥–ª—è LLM
        header = f"[–§—Ä–∞–≥–º–µ–Ω—Ç {i} –∏–∑ {total}, {location}]"
        fragments.append(f"{header}\n{doc.page_content}")
    
    return "\n\n---\n\n".join(fragments)


def build_prompt(context: str, question: str) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM."""
    return SYSTEM_PROMPT.format(context=context, question=question)


# --- Query Expansion ---

QUERY_EXPANSION_PROMPT = """–†–∞—Å—à–∏—Ä—å –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏.

–ó–∞–ø—Ä–æ—Å: {question}

–î–æ–±–∞–≤—å:
- –°–∏–Ω–æ–Ω–∏–º—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º
- –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç—ã —Ç–µ—Ä–º–∏–Ω–æ–≤
- –°–≤—è–∑–∞–Ω–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û —Å–ø–∏—Å–∫–æ–º —Å–ª–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π.
–ü—Ä–∏–º–µ—Ä: "–≤–∏–¥—ã –ø—Ä–∏–±—ã–ª–∏ –≤–∞–ª–æ–≤–∞—è –ø—Ä–∏–±—ã–ª—å gross profit —á–∏—Å—Ç–∞—è –ø—Ä–∏–±—ã–ª—å net income EBITDA retained earnings"

–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å:"""


def expand_query(question: str, llm) -> str:
    """
    –†–∞—Å—à–∏—Ä—è–µ—Ç –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏.
    –ü–æ–º–æ–≥–∞–µ—Ç –Ω–∞–π—Ç–∏ —á–∞–Ω–∫–∏ —Å –∞–Ω–≥–ª–∏–π—Å–∫–∏–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏ –∏ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏.
    """
    prompt = QUERY_EXPANSION_PROMPT.format(question=question)
    try:
        expanded = llm.invoke(prompt)
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        result = f"{question} {expanded.strip()}"
        return result
    except Exception:
        return question  # Fallback –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É


# --- –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ---

def format_source(doc) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫.
    
    –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å HybridChunker: "book.pdf [–ì–ª–∞–≤–∞ 2 > –í–∏–¥—ã –ø—Ä–∏–±—ã–ª–∏]"
    –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç —Å page: "book.pdf [—Å—Ç—Ä. 23]"
    """
    filename = os.path.basename(doc.metadata.get("source", "unknown"))
    
    # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: headings –æ—Ç HybridChunker
    section = doc.metadata.get("section")
    if section:
        return f"{filename} [{section}]"
    
    # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç: page number
    page_label = doc.metadata.get("page_label")
    if page_label:
        return f"{filename} [—Å—Ç—Ä. {page_label}]"
    
    page_num = doc.metadata.get("page")
    if page_num is not None:
        return f"{filename} [—Å—Ç—Ä. {page_num + 1}]"
    
    return filename


def format_sources(docs: list) -> list[str]:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∏ –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Ä—è–¥–æ–∫ –ø–µ—Ä–≤–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è.
    """
    # DEBUG: –ø–æ–∫–∞–∑–∞—Ç—å —Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ –Ω–∞–π–¥–µ–Ω–æ
    print(f"[DEBUG] –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(docs)}")
    for i, doc in enumerate(docs):
        section = doc.metadata.get("section", "")
        preview = doc.page_content[:80].replace("\n", " ")
        print(f"  [{i+1}] {section}: {preview}...")
    
    seen = set()
    result = []
    for doc in docs:
        source = format_source(doc)
        if source not in seen:
            seen.add(source)
            result.append(source)
    return result



# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ ---

def ask_question(
    retriever,
    llm,
    question: str,
    messages: list[dict],
) -> tuple[str, list]:
    """
    –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏—Å–ø–æ–ª—å–∑—É—è retriever –∏ llm –ù–ê–ü–†–Ø–ú–£–Æ.
    
    –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º RetrievalQA chain!
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (answer, docs) –≥–¥–µ docs ‚Äî —Å–ø–∏—Å–æ–∫ Document –¥–ª—è sources.
    """
    # 1. –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –≤–æ–ø—Ä–æ—Å —Å –∏—Å—Ç–æ—Ä–∏–µ–π
    full_question = build_full_question(question, messages)
    
    # 1.5 Query Expansion: —Ä–∞—Å—à–∏—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
    if ENABLE_QUERY_EXPANSION:
        search_query = expand_query(full_question, llm)
    else:
        search_query = full_question
    
    # 2. –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã (—à–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç)
    # –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ ‚Äî invoke, fallback ‚Äî get_relevant_documents
    try:
        docs = retriever.invoke(search_query)
    except AttributeError:
        docs = retriever.get_relevant_documents(search_query)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Å–ø–∏—Å–æ–∫
    if not isinstance(docs, list):
        docs = list(docs) if docs else []
    
    # 3. –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ ‚Äî –ù–ï –≤—ã–∑—ã–≤–∞–µ–º LLM
    if not docs:
        return "–í –∫–Ω–∏–≥–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É.", []
    
    # 4. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
    context = format_context(docs)
    prompt = build_prompt(context, full_question)
    answer = llm.invoke(prompt)
    
    # 5. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    return answer, docs


# --- Stage 4: Streamlit UI ---

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è Streamlit –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    st.set_page_config(
        page_title="RAG —á–∞—Ç–±–æ—Ç –ø–æ PDF",
        page_icon="üìö",
        layout="wide",
    )
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.title("üìö RAG —á–∞—Ç–±–æ—Ç –ø–æ PDF")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ –∏–∑ env
    index_dir = get_env_str("INDEX_DIR", DEFAULT_INDEX_DIR)
    books_dir = get_env_str("BOOKS_DIR", "books/")
    top_k = get_env_int("TOP_K", DEFAULT_TOP_K)
    ollama_model = get_env_str("OLLAMA_MODEL", DEFAULT_OLLAMA_MODEL)
    
    # --- Sidebar ---
    with st.sidebar:
        st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
        
        # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —á–∞—Ç–∞
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç", use_container_width=True):
            st.session_state.messages = []
            st.rerun()
        
        st.divider()
        
        # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–∏ –∏–Ω–¥–µ–∫—Å–∞
        if st.button("üîÑ –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å", use_container_width=True):
            with st.spinner("–ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –∏–Ω–¥–µ–∫—Å–∞..."):
                # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å circular import
                from rag_setup import rebuild_full_index
                
                success = rebuild_full_index(books_dir, index_dir)
                
                if success:
                    st.cache_resource.clear()
                    st.success("‚úÖ –ò–Ω–¥–µ–∫—Å –ø–µ—Ä–µ—Å–æ–±—Ä–∞–Ω!")
                    st.rerun()
                else:
                    st.error(f"‚ùå –í –ø–∞–ø–∫–µ {books_dir} –Ω–µ—Ç PDF —Ñ–∞–π–ª–æ–≤.")
        
        st.divider()
        
        # –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞
        st.subheader("üìä –°—Ç–∞—Ç—É—Å –∏–Ω–¥–µ–∫—Å–∞")
        config = load_index_config(index_dir)
        
        if config:
            st.success("‚úÖ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω")
            st.caption(f"**PDF:** {config.get('pdf_count', '?')}")
            st.caption(f"**–ß–∞–Ω–∫–æ–≤:** {config.get('chunk_count', '?')}")
            st.caption(f"**Chunker:** {config.get('chunker', 'legacy')}")
            st.caption(f"**Max tokens:** {config.get('max_tokens', config.get('chunk_size', '?'))}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
            if check_embed_model_mismatch(config):
                st.warning("‚ö†Ô∏è EMBED_MODEL –≤ env –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç config.json")
        else:
            st.warning("‚ö†Ô∏è –ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω")
            st.caption("–ü–æ–ª–æ–∂–∏—Ç–µ PDF –≤ books/ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å'")
    
    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∏–Ω–¥–µ–∫—Å–∞ ---
    if not config:
        st.warning(
            "üìÇ **–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω.**\n\n"
            "1. –ü–æ–ª–æ–∂–∏—Ç–µ PDF —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫—É `books/`\n"
            "2. –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É **–ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –∏–Ω–¥–µ–∫—Å** –≤ sidebar\n\n"
            "–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ: `python rag_setup.py`"
        )
        st.stop()
    
    # --- –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ ---
    try:
        vectorstore = load_index(index_dir, config["embed_model"])
        if not vectorstore:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å. –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –µ–≥–æ.")
            st.stop()
        
        retriever = get_retriever(vectorstore, top_k)
        llm = get_llm(ollama_model)
        
    except Exception as e:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        st.stop()
    
    # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama ---
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ –∏–ª–∏ –µ—Å–ª–∏ —Ñ–ª–∞–≥ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
    if "ollama_checked" not in st.session_state:
        with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama..."):
            if not check_ollama_connection(llm):
                st.error(
                    "‚ùå **Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.**\n\n"
                    "–ö–∞–∫ –∏—Å–ø—Ä–∞–≤–∏—Ç—å:\n"
                    "1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama: `ollama serve`\n"
                    f"2. –°–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å: `ollama pull {ollama_model}`"
                )
                st.stop()
            st.session_state.ollama_checked = True
    
    # --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ ---
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if message.get("sources"):
                with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏"):
                    for source in message["sources"]:
                        st.caption(f"‚Ä¢ {source}")
    
    # --- –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è ---
    if user_input := st.chat_input("–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –∫–Ω–∏–≥–∞–º..."):
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        st.session_state.messages.append({
            "role": "user",
            "content": user_input,
        })
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        with st.chat_message("user"):
            st.markdown(user_input)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
        with st.chat_message("assistant"):
            with st.spinner("–î—É–º–∞—é..."):
                try:
                    # –ü–µ—Ä–µ–¥–∞—ë–º –∏—Å—Ç–æ—Ä–∏—é –ë–ï–ó —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–Ω–æ —É–∂–µ –≤ question)
                    history = st.session_state.messages[:-1]
                    answer, docs = ask_question(retriever, llm, user_input, history)
                    sources = format_sources(docs)
                    
                except RuntimeError as e:
                    answer = f"‚ùå –û—à–∏–±–∫–∞: {e}"
                    sources = []
                except Exception as e:
                    answer = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"
                    sources = []
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç
            st.markdown(answer)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            if sources:
                with st.expander("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏", expanded=True):
                    for source in sources:
                        st.caption(f"‚Ä¢ {source}")
                
                # DEBUG: –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–æ–≤
                with st.expander("üîç DEBUG: –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞–Ω–∫–æ–≤", expanded=False):
                    for i, doc in enumerate(docs):
                        section = doc.metadata.get("section", doc.metadata.get("page_label", "?"))
                        st.markdown(f"**[{i+1}] {section}**")
                        st.code(doc.page_content, language=None)
                        st.divider()
            else:
                st.caption("üìñ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: (–Ω–µ—Ç)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        st.session_state.messages.append({
            "role": "assistant",
            "content": answer,
            "sources": sources,
        })


if __name__ == "__main__":
    main()
